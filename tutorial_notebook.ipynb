{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280c2486-cf28-4e32-9b85-3caf4296a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/spacy3/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13eb78f4-b61c-4e56-a1e2-153fb0482523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cfc03-000a-4381-a353-2778f97b2a36",
   "metadata": {},
   "source": [
    "## Bagging to BERT: A tour of applied NLP\n",
    "### Table of Contents\n",
    "* [Data processing](#data)\n",
    "* [Word Counts](#word)\n",
    "* [TF-IDF](#tfidf)\n",
    "* [Topic models](#topic)\n",
    "* [Word vectors](#vectors)\n",
    "* [LSTM](#lstm)\n",
    "* [BERT](#bert)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7e591-7d7b-4d92-8f61-d5bb03af5dd7",
   "metadata": {},
   "source": [
    "### Data processing <a class=\"anchor\" id=\"data\"></a>\n",
    "\n",
    "Up first is some preprocessing.  You'll either need to download the [imdb review data](https://ai.stanford.edu/~amaas/data/sentiment/) and save it to this directory OR download the [processed data](https://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharinghttps://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3c4ac0-5a90-49ef-b03b-378932d13c9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # processing the original data into DataFrame\n",
    "# # here for reference, don't need to run this if you're using reviews.pkl.gz\n",
    "# source_path = Path('./aclImdb/')\n",
    "# #neg_files = source_path.glob('./*/neg/*.txt')\n",
    "# #pos_files = source_path.glob('./*/pos/*.txt')\n",
    "# all_files = []\n",
    "# for f in source_path.glob('./*/*/*.txt'):\n",
    "#     filename = f.as_posix()\n",
    "#     if 'unsup' not in filename:\n",
    "#         # split up into useful components\n",
    "#         _, split, sent, idx = filename.split('/')\n",
    "#         idx = int(idx.split('_')[0])\n",
    "#         all_files.append([idx, split, sent, f.read_text()])\n",
    "# review_df = pd.DataFrame(all_files)\n",
    "# review_df.columns = ['idx', 'split', 'label', 'text']\n",
    "# # some minor html cruft is in here\n",
    "# review_df['text'] = review_df['text'].str.replace('<br /><br />', '')\n",
    "# review_df = review_df.to_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28f61ea-8e62-4d21-8f5a-6e3eb1bed2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can skip here if you already have reviews.pkl.gz\n",
    "review_df = pd.read_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db840c0f-9f6d-4058-9913-356eb700dcd0",
   "metadata": {},
   "source": [
    "### Word counts  <a class=\"anchor\" id=\"data\"></a>\n",
    "A very basic way to use a sanitized list of tokens is to do a word count. This unlocks a lot of insights right off and is an important step in exploratory data analysis in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2646a7d-b0f4-406d-bb68-7f5351b425b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n",
      " Alan Rickman & Emma Thompson give good performances with southern/New Orleans accents in this detective flick. It's worth seeing for their scenes- and Rickman's scene with Hal Holbrook. These three actors mannage to entertain us no matter what the movie, it seems. The plot for the movie shows potential, but one gets the impression in watching the film that it was not pulled off as well as it could have been. The fact that it is cluttered by a rather uninteresting subplot and mostly uninteresting kidnappers really muddles things. The movie is worth a view- if for nothing more than entertaining performances by Rickman, Thompson, and Holbrook. \n",
      "\n",
      "Positive\n",
      " Based on an actual story, John Boorman shows the struggle of an American doctor, whose husband and son were murdered and she was continually plagued with her loss. A holiday to Burma with her sister seemed like a good idea to get away from it all, but when her passport was stolen in Rangoon, she could not leave the country with her sister, and was forced to stay back until she could get I.D. papers from the American embassy. To fill in a day before she could fly out, she took a trip into the countryside with a tour guide. \"I tried finding something in those stone statues, but nothing stirred in me. I was stone myself.\" Suddenly all hell broke loose and she was caught in a political revolt. Just when it looked like she had escaped and safely boarded a train, she saw her tour guide get beaten and shot. In a split second she decided to jump from the moving train and try to rescue him, with no thought of herself. Continually her life was in danger. Here is a woman who demonstrated spontaneous, selfless charity, risking her life to save another. Patricia Arquette is beautiful, and not just to look at; she has a beautiful heart. This is an unforgettable story. \"We are taught that suffering is the one promise that life always keeps.\"\n"
     ]
    }
   ],
   "source": [
    "# take a positive and negative review for examples\n",
    "# we'll use Star Wars Episode VI since everyone likes a Star War\n",
    "neg_review = review_df.loc[(review_df.label=='neg')].iloc[0]['text']\n",
    "pos_review = review_df[(review_df.label=='pos')].iloc[0]['text']\n",
    "print('Negative\\n', neg_review, '\\n')\n",
    "print('Positive\\n', pos_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee60e2b-b1b5-4342-9e7e-8e0e3f17538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 4, 'it': 4, 'for': 3, 'and': 3, 'The': 3, 'performances': 2, 'with': 2, 'in': 2, 'worth': 2, 'Holbrook.': 2, 'movie': 2, 'that': 2, 'as': 2, 'is': 2, 'by': 2, 'a': 2, 'uninteresting': 2, 'Alan': 1, 'Rickman': 1, '&': 1, 'Emma': 1, 'Thompson': 1, 'give': 1, 'good': 1, 'southern/New': 1, 'Orleans': 1, 'accents': 1, 'this': 1, 'detective': 1, 'flick.': 1, \"It's\": 1, 'seeing': 1, 'their': 1, 'scenes-': 1, \"Rickman's\": 1, 'scene': 1, 'Hal': 1, 'These': 1, 'three': 1, 'actors': 1, 'mannage': 1, 'to': 1, 'entertain': 1, 'us': 1, 'no': 1, 'matter': 1, 'what': 1, 'movie,': 1, 'seems.': 1, 'plot': 1, 'shows': 1, 'potential,': 1, 'but': 1, 'one': 1, 'gets': 1, 'impression': 1, 'watching': 1, 'film': 1, 'was': 1, 'not': 1, 'pulled': 1, 'off': 1, 'well': 1, 'could': 1, 'have': 1, 'been.': 1, 'fact': 1, 'cluttered': 1, 'rather': 1, 'subplot': 1, 'mostly': 1, 'kidnappers': 1, 'really': 1, 'muddles': 1, 'things.': 1, 'view-': 1, 'if': 1, 'nothing': 1, 'more': 1, 'than': 1, 'entertaining': 1, 'Rickman,': 1, 'Thompson,': 1})\n"
     ]
    }
   ],
   "source": [
    "# base python word count - split on whitespace, use Counter object)\n",
    "print(Counter(neg_review.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c7f82-7e21-42a1-9f70-0c97345ab36a",
   "metadata": {},
   "source": [
    "Already see some things that need to be considered; capitalization treats \"The\" and \"the\" differently, words like \"the\" and \"it\" dominate counts.\n",
    "\n",
    "Luckily, scikit-learn's CountVectorizer allows for simple preprocessing like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3868f067-62e5-4227-9e81-76485ec7cfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x76 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 76 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit-learn's countvectorizer\n",
    "count = CountVectorizer()\n",
    "neg_vec = count.fit_transform([neg_review])\n",
    "neg_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b990345-6215-4e55-845e-53ad8d5c5e80",
   "metadata": {},
   "source": [
    "`CountVectorizer` outputs a sparse matrix by default.  We can convert that to a normal numpy array and stitch it together with the vocabulary from the `fit()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5628123c-2f0a-48b5-afa3-faf6284f60f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accents': 1, 'actors': 1, 'alan': 1, 'and': 3, 'as': 2, 'been': 1, 'but': 1, 'by': 2, 'cluttered': 1, 'could': 1, 'detective': 1, 'emma': 1, 'entertain': 1, 'entertaining': 1, 'fact': 1, 'film': 1, 'flick': 1, 'for': 3, 'gets': 1, 'give': 1, 'good': 1, 'hal': 1, 'have': 1, 'holbrook': 2, 'if': 1, 'impression': 1, 'in': 2, 'is': 2, 'it': 5, 'kidnappers': 1, 'mannage': 1, 'matter': 1, 'more': 1, 'mostly': 1, 'movie': 3, 'muddles': 1, 'new': 1, 'no': 1, 'not': 1, 'nothing': 1, 'off': 1, 'one': 1, 'orleans': 1, 'performances': 2, 'plot': 1, 'potential': 1, 'pulled': 1, 'rather': 1, 'really': 1, 'rickman': 3, 'scene': 1, 'scenes': 1, 'seeing': 1, 'seems': 1, 'shows': 1, 'southern': 1, 'subplot': 1, 'than': 1, 'that': 2, 'the': 7, 'their': 1, 'these': 1, 'things': 1, 'this': 1, 'thompson': 2, 'three': 1, 'to': 1, 'uninteresting': 2, 'us': 1, 'view': 1, 'was': 1, 'watching': 1, 'well': 1, 'what': 1, 'with': 2, 'worth': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    dict(zip(count.get_feature_names_out(), \n",
    "             neg_vec.toarray().flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c23b3-8d69-4a1b-b2e8-726f88eeb977",
   "metadata": {},
   "source": [
    "We can see the defaults have already done some amount of cleaning for us.\n",
    "\n",
    "#### Deterministic Approach with word counts\n",
    "\n",
    "Let's try a deterministic approach, using word counts and a list of \"positive\" vs \"negative\" words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "251c4e13-03bf-4110-b15a-c128c12c7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = [\"good\", \"great\", \"like\", \"loved\"]\n",
    "neg_words = [\"bad\", \"awful\", \"dislike\", \"hated\"]\n",
    "\n",
    "# we're going to use this train/test split throughout\n",
    "# we'll also use this seed for consistency\n",
    "# NOTE: Usually you'll want to do a separate validation set when choosing models/featuresets!\n",
    "seed = 37\n",
    "np.random.seed(seed)\n",
    "pct_train = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_df['text'],\n",
    "    review_df['label'], train_size=pct_train)\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "train_vecs = cv.fit_transform(X_train)\n",
    "feats = cv.get_feature_names_out()\n",
    "pos_idxs = np.where(np.isin(feats, pos_words))[0]\n",
    "neg_idxs = np.where(np.isin(feats, neg_words))[0]\n",
    "train_det_score = train_vecs[:, pos_idxs].sum(1) - train_vecs[:, neg_idxs].sum(1)\n",
    "# easier for group-level score\n",
    "train_det_score = pd.Series(np.array(train_det_score).ravel(), \n",
    "                            index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765c8284-bb84-46e1-982e-928e140eeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our threshold - the average score for negative, that or below = negative\n",
    "neg_thresh = train_det_score.groupby(review_df['label'].loc[X_train.index]).mean()['neg']\n",
    "test_vecs = cv.transform(X_test)\n",
    "test_det_score = test_vecs[:, pos_idxs].sum(1) - test_vecs[:, neg_idxs].sum(1)\n",
    "det_pred = test_det_score>neg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ea3fdf-6cb4-4602-a384-dd05460ac21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.44      0.51      7522\n",
      "        True       0.56      0.71      0.63      7478\n",
      "\n",
      "    accuracy                           0.58     15000\n",
      "   macro avg       0.58      0.58      0.57     15000\n",
      "weighted avg       0.58      0.58      0.57     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(y_pred=det_pred,\n",
    "                          y_true=y_test=='pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f69c5-72b7-4ae9-8ed8-969818832c07",
   "metadata": {},
   "source": [
    "#### Count Vector + Logistic Regression\n",
    "Here we try a count vector with Logistic Regression.  This alleviates the need for chosing an arbitrary set of terms and arbitrary threshold as above.\n",
    "\n",
    "Here I use scikit-learn's [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) functionality.  I won't try and explain that here, the docs do a much better job than I can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25a9d696-97ba-415d-84d2-503844edf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english')\n",
    "\n",
    "count_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", count),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "952acf7e-5a15-4bb8-88d1-258a634e5cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "count_pipeline.fit(X_train, y_train)\n",
    "count_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f58d9f7f-53b2-4cbb-92e6-2d5bac6dcf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.88      0.88      7522\n",
      "         pos       0.88      0.89      0.88      7478\n",
      "\n",
      "    accuracy                           0.88     15000\n",
      "   macro avg       0.88      0.88      0.88     15000\n",
      "weighted avg       0.88      0.88      0.88     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(y_pred=count_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30256a1-982a-4aee-877c-7a7045580aa2",
   "metadata": {},
   "source": [
    "This is actually really good! 90% of the time we're predicting the right class with this model.  But can we do...better?\n",
    "\n",
    "### TF-IDF <a class=\"anchor\" id=\"tfidf\"></a>\n",
    "One thing we notice with count vectors is that all words are being counted the same.  We might want to use a weighting scheme to ensure that words that are more informative about the content are flagged as more important.  One weighting scheme is Term Frequency - Inverse Document Frequency (TF-IDF).\n",
    "\n",
    "Take as an example some kind of simplistic movie reviews.  We can already tell which words are most relevant to the specific content of each review (i.e. \"good\", \"bad\", \"great\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "385e0955-d159-4d27-8508-c1a5645a6dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>movie</th>\n",
       "      <th>the</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad  good  great  movie  the  was\n",
       "0    0     1      0      1    1    1\n",
       "1    1     0      0      1    1    1\n",
       "2    0     0      1      1    1    1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ['The movie was good',\n",
    "        'The movie was bad',\n",
    "        'The movie was great']\n",
    "\n",
    "cv = CountVectorizer()\n",
    "vecs = cv.fit_transform(docs).toarray()\n",
    "# we'll use pandas DF for easier display\n",
    "pd.DataFrame(vecs, columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d93d3-aa56-4599-bd57-bd4e12232445",
   "metadata": {},
   "source": [
    "You'll notice that `vecs` contains the term frequencies.  If we use sklearn's `TfidfVectorizer`, it will calculate those term counts and then multiply them by the Inverse Document Frequency (IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30f3611e-8860-411c-b297-e9d2eedca714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>movie</th>\n",
       "      <th>the</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69903</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.69903</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69903</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bad     good    great     movie       the       was\n",
       "0  0.00000  0.69903  0.00000  0.412859  0.412859  0.412859\n",
       "1  0.69903  0.00000  0.00000  0.412859  0.412859  0.412859\n",
       "2  0.00000  0.00000  0.69903  0.412859  0.412859  0.412859"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "# we'll use pandas DF for easier display\n",
    "tfidf_vecs = tfidf.fit_transform(docs).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_vecs, columns=tfidf.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464164b-5882-48d7-8bb9-f48008ca8d92",
   "metadata": {},
   "source": [
    "You can see that the discriminative words have higher weight than the non-discriminative words.  \n",
    "\n",
    "It's worth noting here - in terms of \"separability\", having 0 v 1 (count of \"good\" vs count of \"bad\") might actually be better.  But these are highly curated examples - you can imagine cases where good and bad descriptive terms are mixed in a review, you want to capture the words that describe better the \"aboutness\" of the review.  (Think: \"This movie was not bad, it was good!\")\n",
    "\n",
    "Now let's fit our regression as above with TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28f28bdf-371d-4dd7-a25b-63376f3f76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use binary here to handle longer reviews\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", tfidf),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c7f2b41-18ed-4fab-adee-d5b7bd44c90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8912666666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "tfidf_pipeline.fit(X_train, y_train)\n",
    "print(f'accuracy: {tfidf_pipeline.score(X_test, y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=tfidf_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10b5b18b-9e54-4ba9-afd3-9a63318aa93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6408</th>\n",
       "      <td>awful</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6697</th>\n",
       "      <td>bad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10324</th>\n",
       "      <td>boring</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22357</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22360</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27335</th>\n",
       "      <td>excellent</td>\n",
       "      <td>89233.0</td>\n",
       "      <td>89227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28106</th>\n",
       "      <td>fails</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34078</th>\n",
       "      <td>great</td>\n",
       "      <td>89234.0</td>\n",
       "      <td>89112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50143</th>\n",
       "      <td>mediocre</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51096</th>\n",
       "      <td>mildly</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52920</th>\n",
       "      <td>mst3k</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58910</th>\n",
       "      <td>perfect</td>\n",
       "      <td>89232.0</td>\n",
       "      <td>89234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60835</th>\n",
       "      <td>poor</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78768</th>\n",
       "      <td>terrible</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86068</th>\n",
       "      <td>waste</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86083</th>\n",
       "      <td>wasting</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87842</th>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word    tfidf    count\n",
       "6408            awful      3.0      4.0\n",
       "6697              bad      2.0    316.0\n",
       "10324          boring      5.0     14.0\n",
       "22357   disappointing     16.0      5.0\n",
       "22360  disappointment     14.0      2.0\n",
       "27335       excellent  89233.0  89227.0\n",
       "28106           fails     17.0      9.0\n",
       "34078           great  89234.0  89112.0\n",
       "50143        mediocre     30.0      6.0\n",
       "51096          mildly     96.0     10.0\n",
       "52920           mst3k     59.0      7.0\n",
       "58910         perfect  89232.0  89234.0\n",
       "60835            poor      6.0     36.0\n",
       "78768        terrible      7.0     20.0\n",
       "86068           waste      4.0      1.0\n",
       "86083         wasting    100.0      8.0\n",
       "87842           worst      1.0      3.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the coefficients on the LR for each model\n",
    "word_feats = tfidf_pipeline['preprocessor'].get_feature_names_out()\n",
    "# get the largest by magnitude, stitch together to compare\n",
    "top = 10\n",
    "top_tfidf = np.argsort(np.abs(tfidf_pipeline['model'].coef_.flatten()))[-top:]\n",
    "top_count = np.argsort(np.abs(count_pipeline['model'].coef_.flatten()))[-top:]\n",
    "# top\n",
    "coef_df = pd.DataFrame([\n",
    "    word_feats,\n",
    "    tfidf_pipeline['model'].coef_.flatten(),\n",
    "    count_pipeline['model'].coef_.flatten()],\n",
    "    index=['word', 'tfidf', 'count']).T\n",
    "# normalize result for compare\n",
    "coef_df['tfidf'] = coef_df['tfidf'].rank()\n",
    "coef_df['count'] = coef_df['count'].rank()\n",
    "coef_df.loc[np.unique(np.concatenate([top_tfidf, top_count]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3e0d90b-ec5f-46ff-a3da-6684ad26778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples where there's disagreement\n",
    "tfidf_pred = tfidf_pipeline.predict_proba(X_test)[:, 1]\n",
    "count_pred = count_pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c456f39f-b53c-4293-aadf-a4725db61123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most interesting are where there's the largest disagreement\n",
    "top_disagree_idx = np.argsort(np.abs(tfidf_pred - count_pred))[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "895f8ac0-64a1-43c4-aeac-ba6488050b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble in df\n",
    "compare_df = pd.DataFrame([tfidf_pred, count_pred, y_test, X_test],\n",
    "            index=['tfidf_pred', 'count_pred', 'label', 'text']).T\n",
    "# would like some shorter mv reviews here\n",
    "compare_df['text'] = compare_df['text'].apply(lambda x: x[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b91b04da-8631-4ce1-ae8c-3a6796572fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df['tfidf_right'] = ((compare_df['tfidf_pred']>=0.5)&(compare_df['label']=='pos'))|\\\n",
    "    ((compare_df['tfidf_pred']<0.5)&(compare_df['label']=='neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7adecafb-b87b-4382-a781-c90d9d0c5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple way to look at some of these differences\n",
    "#compare_df[compare_df.tfidf_right].reindex(top_disagree_idx).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482b4e9-8a10-461a-93bb-cc1806ea8879",
   "metadata": {},
   "source": [
    "It's difficult to see piecemeal, but it does appear that certain words we associate with negative reviews (e.g. \"bad\") have a stronger influence on prediction in the TF-IDF model.\n",
    "\n",
    "### Topic Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59cb1389-29fa-4804-ab71-2ff8eb1d5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c5675d7-407d-4127-9858-42c0faaa7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_components(model, word_features, top_display=5):\n",
    "    # utility for displaying respresentative words per component for topic models\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        top_words_idx = topic.argsort()[::-1][:top_display]\n",
    "        top_words = [word_features[i] for i in top_words_idx]\n",
    "        print(\" \".join(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da41e2dd-e7a9-420f-b7f5-3171fcf5257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit tfidf/cv models\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vecs = tfidf.fit_transform(review_df['text'])\n",
    "#cv = CountVectorizer(stop_words='english', min_df=0.05)\n",
    "#count_vecs = cv.fit_transform(review_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b68b7854-4689-4688-b8b2-bf6aca0de643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the number of components (topics)\n",
    "n_components = 10\n",
    "# adding a few tweaks, just based on experimentation\n",
    "nmf = NMF(n_components=n_components,\n",
    "          init='nndsvda',\n",
    "         max_iter=500)\n",
    "# NMF requires tfidf, not word counts\n",
    "# same syntax as vectorizer\n",
    "nmf_vecs = nmf.fit_transform(tfidf_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b799b42-2e02-4d29-a2d1-cae86544135d",
   "metadata": {},
   "source": [
    "Both NMF and LDA provide a components matrix which corresponds to the loading of each word on each topic.  Higher values means the word is more relevant to that topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7931063-c6e5-45fe-b007-7afbfd011bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.08613596e-03 4.10971444e-02 1.41693238e-04 ... 2.29262679e-04\n",
      "  6.28212910e-05 6.28212910e-05]\n",
      " [7.22501881e-04 0.00000000e+00 0.00000000e+00 ... 1.39870498e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.64404827e-03 6.88220840e-03 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.40469091e-03 1.42849764e-02 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.42327945e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.29440514e-04 1.29440514e-04]\n",
      " [6.79228602e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(nmf.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbfd5b-9abf-4fcb-be65-0ae7463edd9b",
   "metadata": {},
   "source": [
    "For evaluating performance, both methods use different ways to quantify the loss from using the topic model versus the actual data.  (In the matrix formulation, $UV$ rather than $X$).  For NMF, it's reconstruction error, which is more directly the difference between the matrix decomposition and the actual data.  For LDA, it uses [ELBO](https://en.wikipedia.org/wiki/Evidence_lower_bound), which is a too complicated to explain here.  In both, higher values means worse performance.  They can't be compared to one another, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c0d4dac-d531-4cee-a043-ce02eeb0eceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219.17632964934285\n"
     ]
    }
   ],
   "source": [
    "print(nmf.reconstruction_err_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc425a35-ac55-475f-9147-df69f9b45608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "life man story character young\n",
      "Topic 1:\n",
      "movie movies watch book saw\n",
      "Topic 2:\n",
      "bad acting good terrible worst\n",
      "Topic 3:\n",
      "film films director plot making\n",
      "Topic 4:\n",
      "just like don really people\n",
      "Topic 5:\n",
      "great good story really love\n",
      "Topic 6:\n",
      "series episode tv episodes season\n",
      "Topic 7:\n",
      "horror gore budget effects scary\n",
      "Topic 8:\n",
      "funny comedy jokes laugh humor\n",
      "Topic 9:\n",
      "seen ve movies worst time\n"
     ]
    }
   ],
   "source": [
    "display_components(nmf, tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa65e8-fdd1-4b8a-ae3d-9b22d5b29d06",
   "metadata": {},
   "source": [
    "Let's try using this in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f97804ad-78ec-474d-82a5-477eecc35d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use binary here to handle longer reviews\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "nmf = NMF(n_components=n_components,\n",
    "          init='nndsvda',\n",
    "          max_iter=500)\n",
    "\n",
    "nmf_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", tfidf),\n",
    "           (\"topic\", nmf),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "565e1505-3be5-4691-92db-f9cb54a215ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7588666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.80      0.70      0.74      7522\n",
      "         pos       0.73      0.82      0.77      7478\n",
      "\n",
      "    accuracy                           0.76     15000\n",
      "   macro avg       0.76      0.76      0.76     15000\n",
      "weighted avg       0.76      0.76      0.76     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "nmf_pipeline.fit(X_train, y_train)\n",
    "print(f'accuracy: {nmf_pipeline.score(X_test, y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=nmf_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570f38b-f758-458f-b1ef-b7413ef5e9c4",
   "metadata": {},
   "source": [
    "### Word vectors <a class=\"anchor\" id=\"vectors\"></a>\n",
    "Our next approach is to include context in the word-level representations.  We'll be bringing SpaCy into the mix here, particularly their \"medium\" English web model, which uses GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb1334-e39e-4ee3-abd0-8c91acbbe406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33430bf0-6c80-4eae-a807-9a50190659d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run this once\n",
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abdfd44-0837-43a5-8a84-4d27bb70fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b746a-3b95-4519-adfb-b48b111964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GloveVectorizer(BaseEstimator, TransformerMixin):\n",
    "    # this is a custom document transformer for use in the scikit-learn pipeline\n",
    "    def __init__(self, vectorizer):\n",
    "        self.vectorizer = vectorizer\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        vocab = self.vectorizer.vocabulary_\n",
    "        self.vocab_glove = np.zeros(shape=(len(vocab), 300))\n",
    "        for token, idx in vocab.items():\n",
    "            self.vocab_glove[idx] = nlp(token).vector\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = self.vectorizer.transform(X).toarray()\n",
    "        sum_words = (X_transformed.sum(1)).reshape(-1, 1)\n",
    "        glove_vecs = (X_transformed.dot(self.vocab_glove))/sum_words\n",
    "        return glove_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d405e-ebaf-49f9-b83c-a8794ab4abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use binary here to handle longer reviews\n",
    "count = CountVectorizer(stop_words='english', min_df=0.01, binary=False)\n",
    "glove = GloveVectorizer(count)\n",
    "\n",
    "glove_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", glove),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10c82b-b418-4f60-9f65-e0208bd3097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "glove_pipeline.fit(X_train, y_train)\n",
    "glove_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503d51d-d428-4bff-91df-264379d324fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(y_pred=glove_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746651a7-efe3-4098-a9c9-50d971baa113",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "618ef683-7326-4f1c-b5d5-7e67fd4d9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# this will set the device on which to train\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a34655d0-8532-4ad3-9a46-02f9b2b390cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Module):\n",
    "    # sentiment classifier with single LSTM layer + Fully-connected layer, sigmoid activation and dropout\n",
    "    # adapted from https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/\n",
    "    def __init__(self,\n",
    "                 weight_matrix=None,\n",
    "                 vocab_size=None, \n",
    "                 output_size=1,  \n",
    "                 hidden_dim=512,\n",
    "                 embedding_dim=400, \n",
    "                 n_layers=2, \n",
    "                 dropout_prob=0.5):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        # size of the output, in this case it's one input to one output\n",
    "        self.output_size = output_size\n",
    "        # number of layers (default 2) one LSTM layer, one fully-connected layer\n",
    "        self.n_layers = n_layers\n",
    "        # dimensions of our hidden state, what is passed from one time point to the next\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # initialize the representation to pass to the LSTM\n",
    "        self.embedding, embedding_dim = self.init_embedding(\n",
    "            vocab_size, \n",
    "            embedding_dim, \n",
    "            weight_matrix)\n",
    "        # LSTM layer, where the magic happens\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=dropout_prob, batch_first=True)\n",
    "        # dropout, similar to regularization\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        # sigmoid activiation\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # forward pass of the network\n",
    "        batch_size = x.size(0)\n",
    "        # transform input\n",
    "        embeds = self.embedding(x)\n",
    "        # run input embedding + hidden state through model\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        # reshape\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        # dropout certain pct of connections\n",
    "        out = self.dropout(lstm_out)\n",
    "        # fully connected layer\n",
    "        out = self.fc(out)\n",
    "        # activation function\n",
    "        out = self.sigmoid(out)\n",
    "        # reshape\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        # return the output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_embedding(self, vocab_size, embedding_dim, weight_matrix):\n",
    "        # initializes the embedding\n",
    "        if weight_matrix is None:\n",
    "            if vocab_size is None:\n",
    "                raise ValueError('If no weight matrix, need a vocab size')\n",
    "            # if embedding is a size, initialize trainable\n",
    "            return(nn.Embedding(vocab_size, embedding_dim),\n",
    "                   embedding_dim)\n",
    "        else:\n",
    "            # otherwise use matrix as pretrained\n",
    "            weights = torch.FloatTensor(weight_matrix)\n",
    "            return(nn.Embedding.from_pretrained(weights),\n",
    "                  weights.shape[1])\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # initializes the hidden state\n",
    "        hidden = (torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device),\n",
    "                  torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5e8ff3f2-5c79-40b9-b9d4-91f2ffc8b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.en import English\n",
    "en = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e2234bd7-d40d-45c8-a50d-16f92ce28db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample for quickness\n",
    "sample_review = review_df.sample(frac=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sample_review['text'], sample_review['label']=='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d6e0085b-87dc-4fed-83f6-fcc0401ce65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(doc, model=en):\n",
    "    # a simple tokenizer for individual documents \n",
    "    tokenized_docs = []\n",
    "    parsed = model(doc)\n",
    "    return([t.lower_ for t in parsed if (t.is_alpha)&(not t.is_stop)])\n",
    "\n",
    "def doc_to_index(docs, vocab, tokenizer=simple_tokenizer):\n",
    "    # transform docs into series of indices\n",
    "    docs_idxs = []\n",
    "    for d in docs:\n",
    "        w_idxs = []\n",
    "        d_tokenized = simple_tokenizer(d)\n",
    "        for w in d_tokenized:\n",
    "            if w in vocab:\n",
    "                w_idxs.append(vocab[w])\n",
    "            else:\n",
    "                # unknown token = 1\n",
    "                w_idxs.append(1)\n",
    "        docs_idxs.append(w_idxs)\n",
    "    return(docs_idxs)\n",
    "\n",
    "def pad_sequence(seqs, seq_len=200):\n",
    "    # function for adding padding to ensure all seq same length\n",
    "    features = np.zeros((len(seqs), seq_len),dtype=int)\n",
    "    for i, seq in enumerate(seqs):\n",
    "        if len(seq) != 0:\n",
    "            features[i, -len(seq):] = np.array(seq)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "59664271-7328-4d64-a067-c9347adf70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to adapt vocab, leave space for padding\n",
    "tfidf = TfidfVectorizer(tokenizer=simple_tokenizer,\n",
    "                       token_pattern=None,\n",
    "                       min_df=0.01)\n",
    "tfidf.fit(X_train)\n",
    "vocab = tfidf.vocabulary_\n",
    "vocab = dict([(v, vocab[v]+2) for v in vocab])\n",
    "vocab['_UNK'] = 1\n",
    "vocab['_PAD'] = 0\n",
    "parsed_train = doc_to_index(X_train, vocab)\n",
    "padded_train = pad_sequence(parsed_train)\n",
    "parsed_test = doc_to_index(X_test, vocab)\n",
    "padded_test = pad_sequence(parsed_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6df50502-d9f1-4704-8210-ebeeaa872bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct datasets for loading by PyTorch\n",
    "train_data = TensorDataset(torch.from_numpy(padded_train), \n",
    "                           torch.from_numpy(y_train.values))\n",
    "test_data = TensorDataset(torch.from_numpy(padded_test), \n",
    "                          torch.from_numpy(y_test.values))\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,\n",
    "                         drop_last=True) # this is to keep the size consistent\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,\n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "37691ceb-8429-43f6-a11a-9a4e55bfd602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (embedding): Embedding(1526, 400)\n",
       "  (lstm): LSTM(400, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "model_params = {'weight_matrix': None,\n",
    "               'output_size': 1,\n",
    "               'hidden_dim': 512,\n",
    "               'n_layers': 2,\n",
    "               'embedding_dim': 400,\n",
    "               'dropout_prob': 0.2,\n",
    "               'vocab_size': vocab_size}\n",
    "\n",
    "model = SentimentNet(**model_params)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbf0b2-a9ee-4511-a568-ea56767d4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# increasing this will make the training take a while on CPU\n",
    "# decrease to 5 if it's taking too long\n",
    "epochs = 1\n",
    "counter = 0\n",
    "print_every = 5\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "#            for inp, lab in val_loader:\n",
    "            for inp, lab in test_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                    valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fb9f2-0a0c-4530-a898-c8cc3d36f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd2316-e1c8-4b49-b790-3a856c80ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy: {nmf_pipeline.score(X_test, y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=nmf_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9536ef-ae86-406f-92f2-8ef3fb07db18",
   "metadata": {},
   "source": [
    "### BERT\n",
    "From [HF tutorials](https://huggingface.co/blog/sentiment-analysis-python).  Default pipeline uses this [distilBERT model](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60eb292-ff25-4f5e-bf00-a7c8672c758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3e58f-5b03-41a2-92f7-69beb3fc0aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy3",
   "language": "python",
   "name": "spacy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

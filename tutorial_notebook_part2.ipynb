{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280c2486-cf28-4e32-9b85-3caf4296a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/spacy3/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13eb78f4-b61c-4e56-a1e2-153fb0482523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cfc03-000a-4381-a353-2778f97b2a36",
   "metadata": {},
   "source": [
    "## Bagging to BERT: A tour of applied NLP\n",
    "### Part 2: Beyond bagging\n",
    "### Table of Contents\n",
    "* [LSTM](#lstm)\n",
    "* [BERT](#bert)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7e591-7d7b-4d92-8f61-d5bb03af5dd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data processing <a class=\"anchor\" id=\"data\"></a>\n",
    "\n",
    "Copied from part 1\n",
    "\n",
    "You'll either need to download the [imdb review data](https://ai.stanford.edu/~amaas/data/sentiment/) and save it to this directory OR download the [processed data](https://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharinghttps://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3c4ac0-5a90-49ef-b03b-378932d13c9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # processing the original data into DataFrame\n",
    "# # here for reference, don't need to run this if you're using reviews.pkl.gz\n",
    "# source_path = Path('./aclImdb/')\n",
    "# #neg_files = source_path.glob('./*/neg/*.txt')\n",
    "# #pos_files = source_path.glob('./*/pos/*.txt')\n",
    "# all_files = []\n",
    "# for f in source_path.glob('./*/*/*.txt'):\n",
    "#     filename = f.as_posix()\n",
    "#     if 'unsup' not in filename:\n",
    "#         # split up into useful components\n",
    "#         _, split, sent, idx = filename.split('/')\n",
    "#         idx = int(idx.split('_')[0])\n",
    "#         all_files.append([idx, split, sent, f.read_text()])\n",
    "# review_df = pd.DataFrame(all_files)\n",
    "# review_df.columns = ['idx', 'split', 'label', 'text']\n",
    "# # some minor html cruft is in here\n",
    "# review_df['text'] = review_df['text'].str.replace('<br /><br />', '')\n",
    "# review_df = review_df.to_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28f61ea-8e62-4d21-8f5a-6e3eb1bed2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can skip here if you already have reviews.pkl.gz\n",
    "review_df = pd.read_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f56964-2e4a-45bb-89d9-1da65ac6307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from part 1: using the same train/test split\n",
    "seed = 37\n",
    "np.random.seed(seed)\n",
    "pct_train = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_df['text'],\n",
    "    review_df['label'], train_size=pct_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746651a7-efe3-4098-a9c9-50d971baa113",
   "metadata": {},
   "source": [
    "### LSTM <a class=\"anchor\" id=\"lstm\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "618ef683-7326-4f1c-b5d5-7e67fd4d9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable \n",
    "# this will set the device on which to train\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a34655d0-8532-4ad3-9a46-02f9b2b390cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size):\n",
    "        super(SentLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to sentiment space\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "        # sigmoid activiation\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        embeds = self.word_embeddings(x)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        pred_space = self.fc(lstm_out)\n",
    "        out = self.sigmoid(pred_space)\n",
    "        # reshape - want to get the last prediction\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out\n",
    "    \n",
    "def simple_tokenizer(doc, model=en):\n",
    "    # a simple tokenizer for individual documents \n",
    "    tokenized_docs = []\n",
    "    parsed = model(doc)\n",
    "    return([t.lower_ for t in parsed if (t.is_alpha)&(not t.is_stop)])\n",
    "\n",
    "def doc_to_index(docs, vocab, tokenizer=simple_tokenizer):\n",
    "    # transform docs into series of indices\n",
    "    docs_idxs = []\n",
    "    for d in docs:\n",
    "        w_idxs = []\n",
    "        d_tokenized = simple_tokenizer(d)\n",
    "        for w in d_tokenized:\n",
    "            if w in vocab:\n",
    "                w_idxs.append(vocab[w])\n",
    "            else:\n",
    "                # unknown token = 1\n",
    "                w_idxs.append(1)\n",
    "        docs_idxs.append(w_idxs)\n",
    "    return(docs_idxs)\n",
    "\n",
    "def pad_sequence(seqs, seq_len=200):\n",
    "    # function for adding padding to ensure all seq same length\n",
    "    features = np.zeros((len(seqs), seq_len),dtype=int)\n",
    "    for i, seq in enumerate(seqs):\n",
    "        if len(seq) != 0:\n",
    "            features[i, -len(seq):] = np.array(seq)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "59664271-7328-4d64-a067-c9347adf70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to adapt vocab, leave space for padding\n",
    "tfidf = TfidfVectorizer(tokenizer=simple_tokenizer,\n",
    "                       token_pattern=None,\n",
    "                       min_df=0.01)\n",
    "tfidf.fit(X_train)\n",
    "vocab = tfidf.vocabulary_\n",
    "vocab = dict([(v, vocab[v]+2) for v in vocab])\n",
    "vocab['_UNK'] = 1\n",
    "vocab['_PAD'] = 0\n",
    "parsed_train = doc_to_index(X_train, vocab)\n",
    "padded_train = pad_sequence(parsed_train)\n",
    "parsed_test = doc_to_index(X_test, vocab)\n",
    "padded_test = pad_sequence(parsed_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6df50502-d9f1-4704-8210-ebeeaa872bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct datasets for loading by PyTorch\n",
    "train_data = TensorDataset(torch.from_numpy(padded_train), \n",
    "                           torch.from_numpy(y_train.values))\n",
    "test_data = TensorDataset(torch.from_numpy(padded_test), \n",
    "                          torch.from_numpy(y_test.values))\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,\n",
    "                         drop_last=True) # this is to keep the size consistent\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,\n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "37691ceb-8429-43f6-a11a-9a4e55bfd602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSimple(\n",
       "  (word_embeddings): Embedding(1534, 400)\n",
       "  (lstm): LSTM(400, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {'output_size': 1,\n",
    "               'hidden_dim': 512,\n",
    "               'embedding_dim': 400,\n",
    "               'vocab_size': vocab_size}\n",
    "model = LSTMSimple(**model_params)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7bcbf0b2-a9ee-4511-a568-ea56767d4900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Step: 5... Loss: 0.686843... Val Loss: 0.688408\n",
      "Validation loss decreased (inf --> 0.688408).  Saving model ...\n",
      "Epoch: 1/1... Step: 10... Loss: 0.710092... Val Loss: 0.662540\n",
      "Validation loss decreased (0.688408 --> 0.662540).  Saving model ...\n",
      "Epoch: 1/1... Step: 15... Loss: 0.666220... Val Loss: 0.669263\n",
      "Epoch: 1/1... Step: 20... Loss: 0.659887... Val Loss: 0.609165\n",
      "Validation loss decreased (0.662540 --> 0.609165).  Saving model ...\n",
      "Epoch: 1/1... Step: 25... Loss: 0.653383... Val Loss: 0.589641\n",
      "Validation loss decreased (0.609165 --> 0.589641).  Saving model ...\n",
      "Epoch: 1/1... Step: 30... Loss: 0.649555... Val Loss: 0.624702\n",
      "Epoch: 1/1... Step: 35... Loss: 0.636202... Val Loss: 0.640866\n"
     ]
    }
   ],
   "source": [
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# increasing this will make the training take a while on CPU\n",
    "# decrease to 5 if it's taking too long\n",
    "epochs = 1\n",
    "counter = 0\n",
    "print_every = 5\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in test_loader:\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out = model(inp)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "214fb9f2-0a0c-4530-a898-c8cc3d36f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch LSTM model\n",
    "model.load_state_dict(torch.load('./state_dict.pt'))\n",
    "num_correct = 0\n",
    "model.eval()\n",
    "pred_collect = np.array([])\n",
    "eval_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in eval_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output = model(inputs)\n",
    "        # takes output, rounds to 0/1\n",
    "        pred = torch.round(output.squeeze())\n",
    "        pred_collect = np.concatenate([\n",
    "          pred_collect,\n",
    "          pred.cpu().numpy()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e4bd2316-e1c8-4b49-b790-3a856c80ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.58      0.66       651\n",
      "        True       0.63      0.79      0.70       599\n",
      "\n",
      "    accuracy                           0.68      1250\n",
      "   macro avg       0.69      0.69      0.68      1250\n",
      "weighted avg       0.70      0.68      0.68      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {np.where(pred_collect == y_test)[0].shape[0]/y_test.shape[0]}')\n",
    "print(\n",
    "    classification_report(y_pred=pred_collect,\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9536ef-ae86-406f-92f2-8ef3fb07db18",
   "metadata": {},
   "source": [
    "### BERT <a class=\"anchor\" id=\"bert\"></a>\n",
    "From [HF tutorials](https://huggingface.co/blog/sentiment-analysis-python).  The sentiment analysis pipeline packages together the tokenizer and the BERT model with a classification layer.  The default pipeline uses this [distilBERT model](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "c60eb292-ff25-4f5e-bf00-a7c8672c758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "24b3e58f-5b03-41a2-92f7-69beb3fc0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some manipulations for speed and to play nice with BERT\n",
    "bert_pred = sentiment_pipeline(X_test.apply(lambda x: x[:512]).head(n=50).tolist())\n",
    "bert_pred = [p['label']=='POSITIVE' for p in bert_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "25afb1f9-1e29-463d-b4f9-50dcdd0c2af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.81      0.88        32\n",
      "        True       0.74      0.94      0.83        18\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.85      0.88      0.86        50\n",
      "weighted avg       0.88      0.86      0.86        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.where(bert_pred == y_test[:50])\n",
    "print(f'accuracy: {np.where(bert_pred == y_test[:50])[0].shape[0]/50}')\n",
    "print(\n",
    "    classification_report(y_pred=bert_pred,\n",
    "                          y_true=y_test[:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba778396-c395-4364-a2dc-4aab7d274765",
   "metadata": {},
   "source": [
    "There it is - you've leveraged a cutting edge model to do sentiment analysis! This performance is pretty good, but our count vectors actually did a few points better.  Maybe there's an opportunity to fine-tune the BERT model specifically to the IMDB review dataset.  Let's try it.\n",
    "\n",
    "NOTE: This takes some time to run, even with the Collab GPU.  You might want to experiment on subsets of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d59127-dd97-4389-b000-0be0a48f7a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy3",
   "language": "python",
   "name": "spacy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
